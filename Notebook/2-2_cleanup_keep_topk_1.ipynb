{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Install required packages and mount Google Drive\n!pip install -q torch torchvision pandas numpy scikit-learn\nfrom google.colab import drive\ndrive.mount('/content/drive')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import sys\nsys.argv = [\"\", \"--results_dir\", \"/content/drive/MyDrive/Alzheimers/Results/HP_Search_Luke_DDP\", \"--csv\", \"resnet50_luke_small_search_ddp.csv\", \"--topk\", \"3\"]\n\n\"\"\"\nDelete all param-keyed checkpoint files except the top-K by (best_val_acc, test_acc).\n\nUsage:\n  python cleanup_keep_topk.py \\\n    --results_dir /content/drive/MyDrive/Alzheimers/Results/HP_Search_Luke_DDP \\\n    --csv resnet50_luke_small_search_ddp.csv \\\n    --topk 3\n\nOptional:\n  --file_globs \"*.pt,*.pth\"          Comma-separated patterns to target\n  --exclude \"final_best*.pt,final_best*.pth\"  Patterns never to delete\n  --recursive                         Search subdirectories too\n  --dry_run                           Show what would be deleted without deleting\n  --verbose                           Print extra details\n\"\"\"\n\nimport argparse\nfrom pathlib import Path\nimport pandas as pd\n\ndef parse_patterns(s: str):\n    return [p.strip() for p in s.split(\",\") if p.strip()]\n\ndef collect_candidates(root: Path, patterns, recursive=False):\n    files = set()\n    if recursive:\n        for pat in patterns:\n            files.update(root.rglob(pat))\n    else:\n        for pat in patterns:\n            files.update(root.glob(pat))\n    return {p for p in files if p.is_file()}\n\ndef matches_any(path: Path, patterns):\n    return any(path.match(pat) for pat in patterns)\n\ndef main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--results_dir\", type=str, required=True, help=\"Directory containing CSV and checkpoints\")\n    ap.add_argument(\"--csv\", type=str, required=True, help=\"CSV filename with metrics and ckpt_path\")\n    ap.add_argument(\"--topk\", type=int, default=3, help=\"How many checkpoints to keep\")\n    ap.add_argument(\"--file_globs\", type=str, default=\"*.pt,*.pth\", help=\"Comma-separated file patterns to consider\")\n    ap.add_argument(\"--exclude\", type=str, default=\"final_best*.pt,final_best*.pth\", help=\"Comma-separated patterns to never delete\")\n    ap.add_argument(\"--recursive\", action=\"store_true\", help=\"Recurse into subdirectories\")\n    ap.add_argument(\"--dry_run\", action=\"store_true\", help=\"Preview deletions only\")\n    ap.add_argument(\"--verbose\", action=\"store_true\", help=\"Verbose output\")\n    args = ap.parse_args()\n\n    out_dir = Path(args.results_dir).expanduser()\n    csv_path = out_dir / args.csv\n    if not csv_path.exists():\n        print(f\"CSV not found: {csv_path}\")\n        return\n\n    df = pd.read_csv(csv_path)\n    if df.empty:\n        print(\"CSV has no rows; nothing to do.\")\n        return\n\n    required_cols = [\"best_val_acc\", \"test_acc\", \"ckpt_path\"]\n    for col in required_cols:\n        if col not in df.columns:\n            print(f\"CSV missing required column: {col}\")\n            return\n\n    # Ensure numeric sort\n    for col in [\"best_val_acc\", \"test_acc\"]:\n        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n\n    df_sorted = df.sort_values([\"best_val_acc\", \"test_acc\"], ascending=False).reset_index(drop=True)\n\n    keep_names = {Path(r[\"ckpt_path\"]).name for _, r in df_sorted.head(args.topk).iterrows()}\n\n    if args.verbose:\n        print(\"Top-K to keep (by filename):\")\n        for n in keep_names:\n            print(\"  -\", n)\n\n    file_globs = parse_patterns(args.file_globs)\n    exclude_patterns = parse_patterns(args.exclude)\n\n    candidates = collect_candidates(out_dir, file_globs, recursive=args.recursive)\n\n    # Apply excludes\n    candidates = {p for p in candidates if not matches_any(p, exclude_patterns)}\n\n    # Delete everything not in keep set (comparison by basename)\n    to_delete = [p for p in candidates if p.name not in keep_names]\n\n    if args.dry_run:\n        print(f\"[DRY RUN] Would delete {len(to_delete)} files:\")\n        for p in sorted(to_delete):\n            print(\"  \", p)\n        print(f\"[DRY RUN] Would keep {len(candidates) - len(to_delete)} matching files.\")\n        return\n\n    cnt_del = 0\n    for p in to_delete:\n        try:\n            p.unlink()\n            cnt_del += 1\n            if args.verbose:\n                print(\"Deleted:\", p)\n        except Exception as e:\n            print(f\"Failed to delete {p}: {e}\")\n\n    print(f\"Kept top-{args.topk}; deleted {cnt_del} other checkpoints.\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "main()",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
