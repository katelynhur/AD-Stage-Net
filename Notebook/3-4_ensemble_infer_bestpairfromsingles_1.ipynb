{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Install required packages and mount Google Drive\n!pip install -q torch torchvision pandas numpy scikit-learn\nfrom google.colab import drive\ndrive.mount('/content/drive')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import sys\nsys.argv = [\"\", \"--proj_root\", \"/content/drive/MyDrive/Alzheimers\", \"--data_dir\", \"/content/drive/MyDrive/Alzheimers/Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/test\", \"--candidates_json\", \"/content/drive/MyDrive/Alzheimers/Results/Model_Leaderboard/top_for_hybrids.json\", \"--include_families\", \"ResNet,DenseNet,Inception,ResNeXt,EffNet,MobileNetV2,MobileNetV3,VGG\", \"--limit_per_family\", \"3\", \"--search\", \"pair\", \"--one_per_family\", \"1\", \"--out_dir\", \"/content/drive/MyDrive/Alzheimers/Results/EnsembleEval/Pairs_LukeTest_From_Luke\"]\n\n\"\"\"\nEvaluate single or ensemble (late-fusion) models on an ImageFolder dataset.\n- Loads one or more run_dirs (each must contain params.json + best.pt)\n- Runs inference per model with its own eval transform (299 for InceptionV3; 224 otherwise)\n- Averages logits across models (optionally weights) and reports accuracy\n- Can SEARCH best pairs/triples/greedy-K from a candidate pool (e.g., top_for_hybrids.json)\n- Can enforce one-per-family constraint when searching (e.g., 1 ResNet, 1 DenseNet, 1 Inception)\n\nOutputs:\n- <out_dir>/ensemble_results.csv   (ranked results if searching; else a single row)\n- <out_dir>/ensemble_top.md\n- (optional) <out_dir>/preds.csv   (per-sample predictions)\n\nExamples\n--------\n# 1) Evaluate a specific ensemble (no search)\npython ensemble_infer.py \\\n  --proj_root /content/drive/MyDrive/Alzheimers \\\n  --data_dir /content/drive/MyDrive/Alzheimers/Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/test \\\n  --run_dirs \"/content/drive/MyDrive/Alzheimers/Results/ArchSweep/ResNet50/8d028bd145,\\\n/content/drive/MyDrive/Alzheimers/Results/ArchSweep/DenseNet169/313768fef2,\\\n/content/drive/MyDrive/Alzheimers/Results/ArchSweep/InceptionV3/abcd123456\" \\\n  --out_dir /content/drive/MyDrive/Alzheimers/Results/EnsembleEval\n\n# 2) Search best pairs from a pool (from top_for_hybrids.json) with one-per-family\npython ensemble_infer.py \\\n  --proj_root /content/drive/MyDrive/Alzheimers \\\n  --data_dir /content/drive/MyDrive/Alzheimers/Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/test \\\n  --candidates_json /content/drive/MyDrive/Alzheimers/Results/Model_Leaderboard/top_for_hybrids.json \\\n  --include_families \"ResNet,DenseNet,Inception\" \\\n  --limit_per_family 2 \\\n  --search pair \\\n  --one_per_family 1 \\\n  --out_dir /content/drive/MyDrive/Alzheimers/Results/EnsembleEval\n\n# 3) Search best triples from a manual pool (use run_dirs directly)\npython ensemble_infer.py \\\n  --proj_root /content/drive/MyDrive/Alzheimers \\\n  --data_dir /content/drive/MyDrive/Alzheimers/Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/test \\\n  --run_dirs \"/path/A,/path/B,/path/C,/path/D\" \\\n  --search triple \\\n  --out_dir /content/drive/MyDrive/Alzheimers/Results/EnsembleEval\n\n# 4) Greedy K=3 from pool (no family constraint)\npython ensemble_infer.py \\\n  --proj_root /content/drive/MyDrive/Alzheimers \\\n  --data_dir /content/drive/MyDrive/Alzheimers/Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/test \\\n  --run_dirs \"/path/A,/path/B,/path/C,/path/D\" \\\n  --search greedy --k 3 \\\n  --out_dir /content/drive/MyDrive/Alzheimers/Results/EnsembleEval\n\"\"\"\n\nimport os, json, argparse, itertools, math\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import models, datasets, transforms\nfrom torchvision.transforms import InterpolationMode\nfrom torchvision.transforms import functional as F\n\n# ---------- Transforms ----------\nclass PadToSquare:\n    def __call__(self, img):\n        w, h = F.get_image_size(img)\n        s = max(w, h)\n        pad_l = (s - w) // 2\n        pad_r = s - w - pad_l\n        pad_t = (s - h) // 2\n        pad_b = s - h - pad_t\n        return F.pad(img, [pad_l, pad_t, pad_r, pad_b], fill=0)\n\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD  = [0.229, 0.224, 0.225]\n\ndef make_eval_tf(size: int):\n    return transforms.Compose([\n        PadToSquare(),\n        transforms.Resize((size, size), interpolation=InterpolationMode.BICUBIC, antialias=True),\n        transforms.ToTensor(),\n        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n    ])\n\n# ---------- Family mapping ----------\ndef family_of(arch: str) -> str:\n    a = (arch or \"\").lower()\n    if \"resnext\" in a: return \"ResNeXt\"\n    if \"resnet\"  in a: return \"ResNet\"\n    if \"densenet\" in a: return \"DenseNet\"\n    if \"inception\" in a: return \"Inception\"\n    if \"efficientnet\" in a or \"effnet\" in a: return \"EffNet\"\n    if \"mobilenetv3\" in a: return \"MobileNetV3\"\n    if \"mobilenetv2\" in a: return \"MobileNetV2\"\n    if \"vgg\" in a: return \"VGG\"\n    if \"cnn_small\" in a: return \"CNN_Small\"\n    return \"Other\"\n\n# ---------- Models (match your training builders) ----------\ndef _resnet(ctor, num):\n    m = ctor(weights=None)  # we load our checkpoint next\n    in_dim = m.fc.in_features\n    m.fc = nn.Linear(in_dim, num)\n    return m\n\ndef _densenet(ctor, num):\n    m = ctor(weights=None)\n    in_dim = m.classifier.in_features\n    m.classifier = nn.Linear(in_dim, num)\n    return m\n\ndef _effnet(ctor, num):\n    m = ctor(weights=None)\n    in_dim = m.classifier[1].in_features\n    m.classifier[1] = nn.Linear(in_dim, num)\n    return m\n\ndef _mobilenet(ctor, num):\n    m = ctor(weights=None)\n    in_dim = m.classifier[-1].in_features\n    m.classifier[-1] = nn.Linear(in_dim, num)\n    return m\n\ndef _vgg(ctor, num):\n    m = ctor(weights=None)\n    in_dim = m.classifier[-1].in_features\n    m.classifier[-1] = nn.Linear(in_dim, num)\n    return m\n\ndef build_inception(num_classes):\n    m = models.inception_v3(weights=None, aux_logits=True)\n    in_dim = m.fc.in_features\n    m.fc = nn.Linear(in_dim, num_classes)\n    return m\n\nclass YourSmallCNN(nn.Module):\n    def __init__(self, num_classes: int):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classifier = nn.Linear(128, num_classes)\n    def forward(self, x): return self.classifier(self.features(x).view(x.size(0), -1))\n\nMODEL_REGISTRY_224 = {\n    \"CNN_Small\":            lambda num: YourSmallCNN(num),\n    \"ResNet50\":             lambda num: _resnet(models.resnet50, num),\n    \"ResNet101\":            lambda num: _resnet(models.resnet101, num),\n    \"ResNet152\":            lambda num: _resnet(models.resnet152, num),\n    \"DenseNet121\":          lambda num: _densenet(models.densenet121, num),\n    \"DenseNet161\":          lambda num: _densenet(models.densenet161, num),\n    \"DenseNet169\":          lambda num: _densenet(models.densenet169, num),\n    \"DenseNet201\":          lambda num: _densenet(models.densenet201, num),\n    \"EffNetB0\":             lambda num: _effnet(models.efficientnet_b0, num),\n    \"MobileNetV2\":          lambda num: _mobilenet(models.mobilenet_v2, num),\n    \"MobileNetV3_L\":        lambda num: _mobilenet(models.mobilenet_v3_large, num),\n    \"ResNeXt50_32x4d\":      lambda num: _resnet(models.resnext50_32x4d, num),\n    \"ResNeXt101_32x8d\":     lambda num: _resnet(models.resnext101_32x8d, num),\n    \"VGG16\":                lambda num: _vgg(models.vgg16_bn, num),\n}\n\ndef build_model_from_params(params: dict, num_classes: int):\n    arch = params[\"arch\"]\n    dp = float(params.get(\"dropout\", 0.0) or 0.0)\n\n    if arch == \"InceptionV3\":\n        m = build_inception(num_classes)\n    elif arch in MODEL_REGISTRY_224:\n        m = MODEL_REGISTRY_224[arch](num_classes)\n    else:\n        raise ValueError(f\"Unknown arch: {arch}\")\n\n    # IMPORTANT: replicate training-time head structure for correct key names\n    m = add_head_dropout_eval(m, arch, dp, num_classes)\n    return m\n\ndef infer_logits_for_model(run_dir: Path, data_dir: Path, device: torch.device, batch_size=64, num_workers=4):\n    \"\"\"Return (logits: [N,C] np.float32, labels: [N] int64, info: dict)\"\"\"\n    params = json.loads((run_dir / \"params.json\").read_text())\n    arch = params[\"arch\"]\n    size = 299 if arch.lower().startswith(\"inception\") else 224\n    tf = make_eval_tf(size)\n\n    # Base dataset to lock order\n    base = datasets.ImageFolder(str(data_dir), transform=transforms.Compose([transforms.ToTensor()]))\n    ds = datasets.ImageFolder(str(data_dir), transform=tf)\n\n    # Assert identical file order & class mapping\n    assert len(base.samples) == len(ds.samples), \"Dataset size mismatch\"\n    assert base.class_to_idx == ds.class_to_idx, \"Class mapping mismatch\"\n    for (p1, y1), (p2, y2) in zip(base.samples, ds.samples):\n        if p1 != p2 or y1 != y2:\n            raise RuntimeError(\"Sample ordering mismatch between base and tf datasets\")\n\n    labels = np.array([y for _, y in base.samples], dtype=np.int64)\n    num_classes = len(base.classes)\n\n    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n                        pin_memory=True, persistent_workers=(num_workers>0))\n\n    model = build_model_from_params(params, num_classes).to(device)\n    state = torch.load(run_dir / \"best.pt\", map_location=\"cpu\")\n    model.load_state_dict(state, strict=True)\n    model.eval()\n\n    all_logits = []\n    with torch.no_grad():\n        for xb, _ in loader:\n            xb = xb.to(device, non_blocking=True)\n            out = model(xb)\n            if arch.lower().startswith(\"inception\") and isinstance(out, tuple):\n                out = out[0]\n            all_logits.append(out.detach().cpu().float())\n    logits = torch.cat(all_logits, dim=0).numpy()\n    info = {\n        \"arch\": arch,\n        \"family\": family_of(arch),\n        \"run_dir\": str(run_dir),\n        \"cfg_hash\": params.get(\"cfg_hash\"),\n        \"img_size\": size,\n    }\n    return logits.astype(np.float32), labels, info\n\ndef accuracy_from_logits(logits_sum: np.ndarray, labels: np.ndarray) -> float:\n    preds = logits_sum.argmax(axis=1)\n    return (preds == labels).mean().item()\n\ndef softmax(x: np.ndarray) -> np.ndarray:\n    x = x - x.max(axis=1, keepdims=True)\n    e = np.exp(x)\n    return e / e.sum(axis=1, keepdims=True)\n\n# ---------- Search helpers ----------\ndef combos_k(items: List[int], k: int):\n    return itertools.combinations(items, k)\n\ndef greedy_select(logits_bank: List[np.ndarray], labels: np.ndarray, k: int, one_per_family: bool, fams: List[str]):\n    selected = []\n    used_fams = set()\n    current_sum = None\n    for step in range(k):\n        best_gain, best_idx, best_sum = -1, None, None\n        for i, logit in enumerate(logits_bank):\n            if i in selected: continue\n            if one_per_family and fams[i] in used_fams: continue\n            candidate_sum = logit if current_sum is None else (current_sum + logit)\n            acc = accuracy_from_logits(candidate_sum, labels)\n            gain = acc - (accuracy_from_logits(current_sum, labels) if current_sum is not None else 0.0)\n            if acc > best_gain + (0 if current_sum is None else 0):  # favor higher final acc\n                best_gain, best_idx, best_sum = acc, i, candidate_sum\n        if best_idx is None:\n            break\n        selected.append(best_idx)\n        current_sum = best_sum\n        if one_per_family:\n            used_fams.add(fams[best_idx])\n    final_acc = accuracy_from_logits(current_sum, labels) if current_sum is not None else 0.0\n    return selected, final_acc\n\ndef add_head_dropout_eval(model: nn.Module, arch: str, dp: float, num_classes: int):\n    if dp is None or dp <= 0:\n        return model\n    # ResNet-style heads\n    if hasattr(model, \"fc\") and isinstance(model.fc, nn.Linear):\n        in_dim = model.fc.in_features\n        model.fc = nn.Sequential(nn.Dropout(dp), nn.Linear(in_dim, num_classes))\n        return model\n    # Classifier-style heads (DenseNet, MobileNet, VGG, EfficientNet)\n    if hasattr(model, \"classifier\"):\n        if isinstance(model.classifier, nn.Sequential):\n            # replace last Linear and ensure a Dropout right before it\n            seq = list(model.classifier)\n            last_lin_idx = None\n            for i in reversed(range(len(seq))):\n                if isinstance(seq[i], nn.Linear):\n                    last_lin_idx = i\n                    break\n            if last_lin_idx is not None:\n                in_dim = seq[last_lin_idx].in_features\n                seq[last_lin_idx] = nn.Linear(in_dim, num_classes)\n                if last_lin_idx == 0 or not isinstance(seq[last_lin_idx - 1], nn.Dropout):\n                    seq.insert(last_lin_idx, nn.Dropout(dp))\n                model.classifier = nn.Sequential(*seq)\n                return model\n        elif isinstance(model.classifier, nn.Linear):\n            in_dim = model.classifier.in_features\n            model.classifier = nn.Sequential(nn.Dropout(dp), nn.Linear(in_dim, num_classes))\n            return model\n    return model\n\n# ---------- Main ----------\ndef main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--proj_root\", type=str, required=True)\n    ap.add_argument(\"--data_dir\", type=str, required=True, help=\"ImageFolder root to evaluate on (e.g., Luke test)\")\n    ap.add_argument(\"--run_dirs\", type=str, default=\"\", help=\"Comma-separated list of run_dir paths (pool and/or fixed ensemble)\")\n    ap.add_argument(\"--candidates_json\", type=str, default=\"\", help=\"Optional JSON (e.g., top_for_hybrids.json)\")\n    ap.add_argument(\"--include_families\", type=str, default=\"\", help=\"Limit candidates to these families (comma-separated)\")\n    ap.add_argument(\"--limit_per_family\", type=int, default=0, help=\"Cap number per family from candidates_json (0 = no cap)\")\n    ap.add_argument(\"--search\", type=str, default=\"none\", choices=[\"none\",\"pair\",\"triple\",\"greedy\"], help=\"Search mode\")\n    ap.add_argument(\"--k\", type=int, default=3, help=\"K for greedy search\")\n    ap.add_argument(\"--one_per_family\", type=int, default=1, help=\"Enforce at most one model per family (for search)\")\n    ap.add_argument(\"--weights\", type=str, default=\"\", help=\"Comma weights for --run_dirs in 'none' mode (default equal)\")\n    ap.add_argument(\"--batch_size\", type=int, default=64)\n    ap.add_argument(\"--num_workers\", type=int, default=4)\n    ap.add_argument(\"--gpus\", type=str, default=\"\", help='Set CUDA_VISIBLE_DEVICES (e.g., \"0\" or \"0,1\"); empty uses default visibility')\n    ap.add_argument(\"--out_dir\", type=str, required=True)\n    ap.add_argument(\"--save_preds\", type=int, default=0, help=\"Write per-sample predictions CSV\")\n    args = ap.parse_args()\n\n    if args.gpus != \"\":\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpus\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    proj_root = Path(os.path.expanduser(args.proj_root))\n    data_dir = Path(os.path.expanduser(args.data_dir))\n    out_dir = Path(os.path.expanduser(args.out_dir))\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    # ---- Build candidate list ----\n    pool: List[Path] = []\n    info_bank: List[Dict] = []\n    logits_bank: List[np.ndarray] = []\n    fams: List[str] = []\n    labels_ref: np.ndarray = None\n\n    # From JSON (shortlists)\n    if args.candidates_json:\n        j = json.loads(Path(os.path.expanduser(args.candidates_json)).read_text())\n        include_fams = [f.strip() for f in args.include_families.split(\",\") if f.strip()] if args.include_families else None\n\n        # Flatten family -> list[dict] (each with run_dir)\n        flat = []\n        for fam, lst in j.items():\n            if include_fams and fam not in include_fams:\n                continue\n            limit = args.limit_per_family if args.limit_per_family > 0 else len(lst)\n            for d in lst[:limit]:\n                if \"run_dir\" in d and d[\"run_dir\"]:\n                    flat.append(Path(d[\"run_dir\"]))\n\n        pool.extend(flat)\n\n    # From explicit --run_dirs\n    if args.run_dirs.strip():\n        extra = [Path(os.path.expanduser(p.strip())) for p in args.run_dirs.split(\",\") if p.strip()]\n        pool.extend(extra)\n\n    # De-dup while preserving order\n    seen = set()\n    uniq_pool = []\n    for p in pool:\n        if str(p) not in seen:\n            uniq_pool.append(p)\n            seen.add(str(p))\n    pool = uniq_pool\n\n    if not pool:\n        raise SystemExit(\"No candidates provided (use --run_dirs and/or --candidates_json).\")\n\n    # ---- Run per-model inference to build logits bank ----\n    for rd in pool:\n        logits, labels, info = infer_logits_for_model(\n            rd, data_dir, device, batch_size=args.batch_size, num_workers=args.num_workers\n        )\n        if labels_ref is None:\n            labels_ref = labels\n        else:\n            if not np.array_equal(labels_ref, labels):\n                raise RuntimeError(\"Label order mismatch across models; check dataset consistency.\")\n        logits_bank.append(logits)\n        info_bank.append(info)\n        fams.append(info[\"family\"])\n        print(f\"[Loaded] {info['arch']} ({info['family']}): {rd}\")\n\n    # ---- If just evaluate a fixed list (no search) ----\n    if args.search == \"none\":\n        weights = None\n        if args.weights.strip():\n            w = [float(x) for x in args.weights.split(\",\")]\n            if len(w) != len(logits_bank):\n                raise SystemExit(\"--weights length must match number of --run_dirs in 'none' mode\")\n            weights = np.array(w, dtype=np.float32)\n        if weights is None:\n            logits_sum = np.sum(logits_bank, axis=0)\n        else:\n            # normalize to sum=1 for stability\n            weights = weights / (weights.sum() + 1e-8)\n            logits_sum = np.zeros_like(logits_bank[0])\n            for w, L in zip(weights, logits_bank):\n                logits_sum += w * L\n        acc = accuracy_from_logits(logits_sum, labels_ref)\n\n        import pandas as pd\n        row = {\n            \"ensemble\": \" + \".join([info[\"arch\"] for info in info_bank]),\n            \"n_models\": len(info_bank),\n            \"acc\": acc,\n            \"members\": [info[\"run_dir\"] for info in info_bank],\n        }\n        df = pd.DataFrame([row])\n        (out_dir / \"ensemble_results.csv\").write_text(df.to_csv(index=False))\n        try:\n            (out_dir / \"ensemble_top.md\").write_text(df.to_markdown(index=False))\n        except Exception:\n            (out_dir / \"ensemble_top.md\").write_text(df.to_string(index=False))\n        print(f\"\\nFixed ensemble accuracy: {acc:.4f}\")\n        if args.save_preds:\n            preds = logits_sum.argmax(1)\n            pd.DataFrame({\"pred\": preds, \"label\": labels_ref}).to_csv(out_dir / \"preds.csv\", index=False)\n        return\n\n    # ---- Search modes ----\n    results = []  # list of (acc, indices_tuple)\n    n = len(logits_bank)\n    one_per_family = bool(args.one_per_family)\n\n    def valid_combo(idx_tuple):\n        if not one_per_family: return True\n        famset = {fams[i] for i in idx_tuple}\n        return len(famset) == len(idx_tuple)\n\n    if args.search in (\"pair\", \"triple\"):\n        k = 2 if args.search == \"pair\" else 3\n        for idxs in combos_k(list(range(n)), k):\n            if not valid_combo(idxs): continue\n            logits_sum = np.zeros_like(logits_bank[0])\n            for i in idxs:\n                logits_sum += logits_bank[i]\n            acc = accuracy_from_logits(logits_sum, labels_ref)\n            results.append((acc, idxs))\n    elif args.search == \"greedy\":\n        sel, acc = greedy_select(logits_bank, labels_ref, k=args.k, one_per_family=one_per_family, fams=fams)\n        results.append((acc, tuple(sel)))\n    else:\n        raise SystemExit(\"Unknown search mode\")\n\n    # Rank and save\n    results.sort(key=lambda x: x[0], reverse=True)\n    import pandas as pd\n    rows = []\n    for acc, idxs in results:\n        members = [info_bank[i][\"run_dir\"] for i in idxs]\n        names   = [info_bank[i][\"arch\"] for i in idxs]\n        fam     = [info_bank[i][\"family\"] for i in idxs]\n        rows.append({\n            \"acc\": acc,\n            \"n_models\": len(idxs),\n            \"members_names\": \" + \".join(names),\n            \"members_families\": \" + \".join(fam),\n            \"members_run_dirs\": \" | \".join(members),\n            \"indices\": list(idxs),\n        })\n    df = pd.DataFrame(rows)\n    df.to_csv(out_dir / \"ensemble_results.csv\", index=False)\n    try:\n        (out_dir / \"ensemble_top.md\").write_text(df.head(30).to_markdown(index=False))\n    except Exception:\n        (out_dir / \"ensemble_top.md\").write_text(df.head(30).to_string(index=False))\n\n    # Save preds for the top-1 combo if asked\n    if args.save_preds and len(results) > 0:\n        _, idxs = results[0]\n        logits_sum = np.zeros_like(logits_bank[0])\n        for i in idxs:\n            logits_sum += logits_bank[i]\n        preds = logits_sum.argmax(1)\n        pd.DataFrame({\"pred\": preds, \"label\": labels_ref}).to_csv(out_dir / \"preds.csv\", index=False)\n\n    print(f\"\\nSaved ranking to {out_dir/'ensemble_results.csv'}\")\n    if len(results) > 0:\n        print(\"Top-1:\", rows[0][\"members_names\"], f\"acc={rows[0]['acc']:.4f}\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "main()\n",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
