{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Install required packages and mount Google Drive\n!pip install -q torch torchvision pandas numpy scikit-learn\nfrom google.colab import drive\ndrive.mount('/content/drive')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import sys\nsys.argv = [\"\", \"--proj_root\", \"/content/drive/MyDrive/Alzheimers\", \"--train_dir\", \"Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/train\", \"--test_dir\", \"Data/Kaggle_LukeChugh_Best_Alzheimers_MRI/test\", \"--results_subdir\", \"Results/ArchSweep\", \"--epochs\", \"20\", \"--batch_size\", \"32\", \"--best_params_json\", \"/content/drive/MyDrive/Alzheimers/Results/HP_Search_Luke_DDP/best_params.json\", \"--gpus\", \"auto\", \"--skip_completed\", \"1\"]\n\n\"\"\"\nTrain multiple architectures with a tiny per-arch sweep, log every epoch, and save best/final checkpoints.\n\nNew:\n- --best_params_json accepts either a GLOBAL dict:\n    {\n      \"lr\": 5e-5,\n      \"label_smoothing\": 0.05,\n      \"dropout\": 0.3,\n      \"weight_decay\": 1e-4,\n      \"batch_size\": 32\n    }\n  or a PER-ARCH dict:\n    {\n      \"ResNet50\": {\"lr\": 5e-5, \"dropout\": 0.2, \"label_smoothing\": 0.05, \"weight_decay\": 1e-4, \"batch_size\": 32},\n      \"EffNetB0\": {...},\n      ...\n    }\n- If provided, these values override CLI defaults when present for that arch.\n- LR grid is centered at the chosen lr × [0.5, 1.0, 2.0].\n- Dropout candidates come from a small arch-aware function seeded by the chosen base dropout.\n- **Auto GPU selection** (default): prefers A800s (via nvidia-smi) and re-execs with CUDA_VISIBLE_DEVICES.\n  Override with --gpus \"0,2,3\" or disable override with --gpus \"\".\n  Backward-compat flag --visible_devices is still accepted.\n- **DDP implementation** with self-launch via torchrun; one process per visible GPU.\n\nArchitectures covered (224x unless noted):\n- CNN_Small (placeholder; enable if desired)\n- ResNet50 / 101 / 152\n- DenseNet121 / 161 / 169 / 201\n- EfficientNet-B0\n- MobileNetV2 / MobileNetV3-Large\n- ResNeXt50_32x4d / ResNeXt101_32x8d\n- VGG16-BN\n- InceptionV3 (299x, aux logits handled)\n\nData assumption (Luke dataset):\n- Train/Val: taken from Luke's 'train' split by an internal stratified split (default 80/20)\n- Test: Luke's 'test' split\n\nOutputs (under <proj_root>/<results_subdir>/):\n- Per-arch, per-config folder:\n  - params.json (what was used)\n  - epoch_log.csv (epoch, train_loss, val_loss, train_acc, val_acc, lr)\n  - best.pt (best val checkpoint, state_dict)   [rank 0 only]\n  - final.pt (last epoch checkpoint, state_dict) [rank 0 only]\n  - complete.txt (marker)                        [rank 0 only]\n- Global CSV: arch_sweep_results.csv (row per config with best val acc, test acc, etc.) [rank 0 only]\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport time\nimport hashlib\nimport random\nimport argparse\nimport warnings\nimport subprocess\nimport shutil\nimport math\nimport gc\nfrom pathlib import Path\nfrom typing import List\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# ----------------------------\n# Early arg parse (for GPU setup)\n# ----------------------------\nap = argparse.ArgumentParser()\nap.add_argument(\"--proj_root\", type=str, required=True)\nap.add_argument(\"--train_dir\", type=str, required=True)  # Luke train\nap.add_argument(\"--test_dir\", type=str, required=True)   # Luke test\nap.add_argument(\"--results_subdir\", type=str, default=\"Results/ArchSweep\")\nap.add_argument(\"--epochs\", type=int, default=20)\nap.add_argument(\"--batch_size\", type=int, default=32)\nap.add_argument(\"--num_workers\", type=int, default=4)\nap.add_argument(\"--best_lr\", type=float, default=5e-5)\nap.add_argument(\"--best_label_smoothing\", type=float, default=0.05)\nap.add_argument(\"--best_dropout\", type=float, default=0.3)\nap.add_argument(\"--weight_decay\", type=float, default=1e-4)\nap.add_argument(\"--val_split\", type=float, default=0.2)\nap.add_argument(\"--best_params_json\", type=str, default=\"\",\n                help=\"Path to best_retrained.json or best_params.json; \"\n                     \"if provided, values inside override defaults (globally or per-arch) when present\")\nap.add_argument(\"--single_best_only\", type=int, default=0,\n                help=\"If 1, disable LR×dropout sweep and train exactly once per arch with best params.\")\nap.add_argument(\"--extra_tests\", type=str, default=\"\",\n                help='Semicolon list like \"Marco:Data/Marco/test;Falah:Data/Falah/test\"')\n\n# GPU control (new): prefer A800s automatically; override with --gpus; legacy --visible_devices honored if set.\nap.add_argument(\"--gpus\", type=str, default=\"auto\",\n                help='GPU selection: \"auto\" (prefer A800s), \"\" (no override), or e.g. \"0,2,3\"')\nap.add_argument(\"--visible_devices\", type=str, default=\"\",\n                help=\"(deprecated) e.g., '0,2,3'; if provided and --gpus is 'auto', this will be used.\")\nap.add_argument(\"--skip_completed\", type=int, default=1)\nargs, _ = ap.parse_known_args()\n\n# ----------------------------\n# Auto GPU selection (A800) + re-exec once\n# ----------------------------\ndef detect_gpu_indices_by_name(match_any: List[str]) -> List[str]:\n    try:\n        out = subprocess.check_output(\n            [\"nvidia-smi\", \"--query-gpu=index,name\", \"--format=csv,noheader\"],\n            stderr=subprocess.STDOUT, text=True\n        )\n    except Exception:\n        return []\n    picks = []\n    for line in out.strip().splitlines():\n        parts = [p.strip() for p in line.split(\",\")]\n        if len(parts) >= 2:\n            idx, name = parts[0], \",\".join(parts[1:]).strip()\n            if any(tok.lower() in name.lower() for tok in match_any):\n                picks.append(idx)\n    return picks\n\ndef ensure_cuda_visibility():\n    # Prevent infinite recursion\n    if os.environ.get(\"_CUDA_VIS_SET\") == \"1\":\n        return\n    os.environ.setdefault(\"CUDA_DEVICE_ORDER\", \"PCI_BUS_ID\")\n\n    # If explicit --gpus is given (including empty string), respect it.\n    if args.gpus != \"auto\":\n        if args.gpus.strip():\n            os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpus.strip()\n        # else: empty string means no override\n        os.environ[\"_CUDA_VIS_SET\"] = \"1\"\n        os.execvpe(sys.executable, [sys.executable] + sys.argv, os.environ)\n\n    # Backward compat: if legacy --visible_devices is set, use it in auto mode.\n    if args.visible_devices:\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.visible_devices\n        os.environ[\"_CUDA_VIS_SET\"] = \"1\"\n        os.execvpe(sys.executable, [sys.executable] + sys.argv, os.environ)\n\n    # Auto mode: prefer A800s if present; otherwise leave as-is.\n    if \"CUDA_VISIBLE_DEVICES\" not in os.environ or os.environ[\"CUDA_VISIBLE_DEVICES\"] == \"\":\n        picks = detect_gpu_indices_by_name([\"A800\"])\n        if picks:\n            os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(picks)\n            os.environ[\"_CUDA_VIS_SET\"] = \"1\"\n            os.execvpe(sys.executable, [sys.executable] + sys.argv, os.environ)\n\nensure_cuda_visibility()\n\ndef self_launch_with_torchrun_if_needed():\n    if os.environ.get(\"LOCAL_RANK\") is not None:\n        return\n    if os.environ.get(\"_SELF_LAUNCHED\") == \"1\":\n        return\n    vis = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\")\n    if vis.strip():\n        nproc = len([x for x in vis.split(\",\") if x.strip() != \"\"])\n    else:\n        # try to count GPUs\n        try:\n            out = subprocess.check_output([\"nvidia-smi\", \"-L\"], text=True)\n            nproc = max(1, len([ln for ln in out.strip().splitlines() if ln.strip()]))\n        except Exception:\n            nproc = 1\n    if nproc <= 1:\n        return  # single process path (no DDP)\n    torchrun = shutil.which(\"torchrun\")\n    if torchrun:\n        cmd = [torchrun, f\"--nproc_per_node={nproc}\", sys.argv[0]]\n    else:\n        cmd = [sys.executable, \"-m\", \"torch.distributed.run\", f\"--nproc_per_node={nproc}\", sys.argv[0]]\n    cmd.extend(sys.argv[1:])\n    env = os.environ.copy()\n    env[\"_SELF_LAUNCHED\"] = \"1\"\n    os.execvpe(cmd[0], cmd, env)\n\nself_launch_with_torchrun_if_needed()\n\n# ----------------------------\n# Now it's safe to import torch/torchvision and set up DDP\n# ----------------------------\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.utils.data import DataLoader, Subset, DistributedSampler\nfrom torchvision import models, transforms, datasets\nfrom torchvision.transforms import InterpolationMode\nfrom torchvision.transforms import functional as F\n\nmp.set_sharing_strategy(\"file_system\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\ndef ddp_setup():\n    if os.environ.get(\"LOCAL_RANK\") is None:\n        # not under torchrun: fallback to single-process / single-GPU or CPU\n        rank, world_size, local_rank = 0, 1, 0\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        return rank, world_size, local_rank, device, False\n    dist.init_process_group(backend=\"nccl\")\n    rank = int(os.environ[\"RANK\"])\n    world_size = int(os.environ[\"WORLD_SIZE\"])\n    local_rank = int(os.environ[\"LOCAL_RANK\"])\n    torch.cuda.set_device(local_rank)\n    device = torch.device(f\"cuda:{local_rank}\")\n    return rank, world_size, local_rank, device, True\n\nrank, world_size, local_rank, device, using_ddp = ddp_setup()\nis_main = (rank == 0)\n\n# ----------------------------\n# Repro\n# ----------------------------\ndef set_seed(seed: int = 42):\n    seed = seed + rank  # different initial seeds across ranks\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n# ----------------------------\n# Transforms (Pad -> Resize)\n# ----------------------------\nclass PadToSquare:\n    def __call__(self, img):\n        w, h = F.get_image_size(img)\n        s = max(w, h)\n        pad_l = (s - w) // 2\n        pad_r = s - w - pad_l\n        pad_t = (s - h) // 2\n        pad_b = s - h - pad_t\n        return F.pad(img, [pad_l, pad_t, pad_r, pad_b], fill=0)\n\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\ndef make_transforms(arch_name: str):\n    size = 299 if arch_name.lower().startswith(\"inception\") else 224\n    tf_train = transforms.Compose([\n        PadToSquare(),\n        transforms.Resize((size, size), interpolation=InterpolationMode.BICUBIC, antialias=True),\n        transforms.RandomHorizontalFlip(0.5),\n        transforms.RandomRotation(10, interpolation=InterpolationMode.BILINEAR),\n        transforms.ToTensor(),\n        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n    ])\n    tf_eval = transforms.Compose([\n        PadToSquare(),\n        transforms.Resize((size, size), interpolation=InterpolationMode.BICUBIC, antialias=True),\n        transforms.ToTensor(),\n        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n    ])\n    return tf_train, tf_eval, size\n\n# ----------------------------\n# Model builders\n# ----------------------------\ndef _resnet(ctor, num):\n    m = ctor(weights=\"IMAGENET1K_V1\")\n    in_dim = m.fc.in_features\n    m.fc = nn.Linear(in_dim, num)\n    return m\n\ndef _densenet(ctor, num):\n    m = ctor(weights=\"IMAGENET1K_V1\")\n    in_dim = m.classifier.in_features\n    m.classifier = nn.Linear(in_dim, num)\n    return m\n\ndef _effnet(ctor, num):\n    m = ctor(weights=\"IMAGENET1K_V1\")\n    in_dim = m.classifier[1].in_features\n    # keep built-in dropout in m.classifier[0]; replace final linear\n    m.classifier[1] = nn.Linear(in_dim, num)\n    return m\n\ndef _mobilenet(ctor, num):\n    m = ctor(weights=\"IMAGENET1K_V1\")\n    in_dim = m.classifier[-1].in_features\n    m.classifier[-1] = nn.Linear(in_dim, num)\n    return m\n\ndef _vgg(ctor, num):\n    m = ctor(weights=\"IMAGENET1K_V1\")\n    in_dim = m.classifier[-1].in_features\n    m.classifier[-1] = nn.Linear(in_dim, num)\n    return m\n\ndef build_inception(num_classes):\n    m = models.inception_v3(weights=\"IMAGENET1K_V1\", aux_logits=True)\n    in_dim = m.fc.in_features\n    m.fc = nn.Linear(in_dim, num_classes)\n    return m\n\n# Placeholder small CNN (swap with your own if desired)\nclass YourSmallCNN(nn.Module):\n    def __init__(self, num_classes: int):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1))\n        )\n        self.classifier = nn.Linear(128, num_classes)\n    def forward(self, x):\n        z = self.features(x)\n        z = z.view(z.size(0), -1)\n        return self.classifier(z)\n\nMODEL_REGISTRY_224 = {\n    \"CNN_Small\": lambda num: YourSmallCNN(num),\n    \"ResNet50\": lambda num: _resnet(models.resnet50, num),\n    \"ResNet101\": lambda num: _resnet(models.resnet101, num),\n    \"ResNet152\": lambda num: _resnet(models.resnet152, num),\n    \"DenseNet121\": lambda num: _densenet(models.densenet121, num),\n    \"DenseNet161\": lambda num: _densenet(models.densenet161, num),\n    \"DenseNet169\": lambda num: _densenet(models.densenet169, num),\n    \"DenseNet201\": lambda num: _densenet(models.densenet201, num),\n    \"EffNetB0\": lambda num: _effnet(models.efficientnet_b0, num),\n    \"MobileNetV2\": lambda num: _mobilenet(models.mobilenet_v2, num),\n    \"MobileNetV3_L\": lambda num: _mobilenet(models.mobilenet_v3_large, num),\n    \"ResNeXt50_32x4d\": lambda num: _resnet(models.resnext50_32x4d, num),\n    \"ResNeXt101_32x8d\": lambda num: _resnet(models.resnext101_32x8d, num),\n    \"VGG16\": lambda num: _vgg(models.vgg16_bn, num),\n    # Inception handled separately for 299\n}\n\n# Insert head dropout if requested (where applicable)\ndef add_head_dropout(model, arch, dp, num_classes):\n    if dp is None or dp <= 0:\n        return model\n    # Common cases:\n    if hasattr(model, \"fc\") and isinstance(model.fc, nn.Linear):\n        in_dim = model.fc.in_features\n        model.fc = nn.Sequential(nn.Dropout(dp), nn.Linear(in_dim, num_classes))\n        return model\n    if hasattr(model, \"classifier\"):\n        if isinstance(model.classifier, nn.Sequential):\n            # replace last Linear and insert dropout before it\n            for i in reversed(range(len(model.classifier))):\n                if isinstance(model.classifier[i], nn.Linear):\n                    in_dim = model.classifier[i].in_features\n                    new_seq = list(model.classifier)\n                    new_seq[i] = nn.Linear(in_dim, num_classes)\n                    if i == 0 or not isinstance(new_seq[i - 1], nn.Dropout):\n                        new_seq.insert(i, nn.Dropout(dp))\n                    model.classifier = nn.Sequential(*new_seq)\n                    return model\n        elif isinstance(model.classifier, nn.Linear):\n            in_dim = model.classifier.in_features\n            model.classifier = nn.Sequential(nn.Dropout(dp), nn.Linear(in_dim, num_classes))\n            return model\n    return model  # fallback: unchanged\n\n# ----------------------------\n# DDP-aware train / eval (global aggregation)\n# ----------------------------\ndef _all_reduce_sum(x: torch.Tensor):\n    if using_ddp and world_size > 1:\n        dist.all_reduce(x, op=dist.ReduceOp.SUM)\n    return x\n\ndef train_one_epoch(model, loader, ce, optimizer, device, arch_name):\n    model.train()\n    loss_sum = torch.tensor(0.0, device=device)\n    correct_sum = torch.tensor(0.0, device=device)\n    total_sum = torch.tensor(0.0, device=device)\n\n    for xb, yb in loader:\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n        out = model(xb)\n        if arch_name.lower().startswith(\"inception\") and isinstance(out, tuple):\n            main_out, aux_out = out\n            loss = ce(main_out, yb) + 0.4 * ce(aux_out, yb)\n            logits = main_out\n        else:\n            loss = ce(out, yb)\n            logits = out\n        loss.backward()\n        optimizer.step()\n\n        bsz = yb.size(0)\n        loss_sum += loss.detach() * bsz\n        correct_sum += (logits.argmax(1) == yb).sum()\n        total_sum += bsz\n\n    # aggregate across ranks\n    loss_sum = _all_reduce_sum(loss_sum)\n    correct_sum = _all_reduce_sum(correct_sum)\n    total_sum = _all_reduce_sum(total_sum)\n\n    total = max(total_sum.item(), 1.0)\n    return float(loss_sum.item() / total), float(correct_sum.item() / total)\n\n@torch.no_grad()\ndef evaluate(model, loader, ce, device, arch_name):\n    model.eval()\n    loss_sum = torch.tensor(0.0, device=device)\n    correct_sum = torch.tensor(0.0, device=device)\n    total_sum = torch.tensor(0.0, device=device)\n\n    for xb, yb in loader:\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n        out = model(xb)\n        if arch_name.lower().startswith(\"inception\") and isinstance(out, tuple):\n            out = out[0]\n        loss = ce(out, yb)\n        bsz = yb.size(0)\n        loss_sum += loss * bsz\n        correct_sum += (out.argmax(1) == yb).sum()\n        total_sum += bsz\n\n    # aggregate across ranks\n    loss_sum = _all_reduce_sum(loss_sum)\n    correct_sum = _all_reduce_sum(correct_sum)\n    total_sum = _all_reduce_sum(total_sum)\n\n    total = max(total_sum.item(), 1.0)\n    return float(loss_sum.item() / total), float(correct_sum.item() / total)\n\n# ----------------------------\n# Utilities\n# ----------------------------\ndef hash_config(d: dict):\n    s = json.dumps(d, sort_keys=True)\n    return hashlib.md5(s.encode()).hexdigest()[:10]\n\ndef write_epoch_csv(path: Path, row: dict):\n    if not is_main:\n        return\n    header = not path.exists()\n    df = pd.DataFrame([row])\n    df.to_csv(path, index=False, header=header, mode=\"a\")\n\ndef evaluate_on_test(model, test_loader, device, arch_name):\n    ce = nn.CrossEntropyLoss()\n    test_loss, test_acc = evaluate(model, test_loader, ce, device, arch_name)\n    return test_loss, test_acc\n\n# Loader shutdown + skip helpers\ndef shutdown_loader(loader):\n    if loader is None:\n        return\n    try:\n        it = getattr(loader, \"_iterator\", None)\n        if it is not None:\n            it._shutdown_workers()  # best-effort; supported in recent PyTorch\n    except Exception:\n        pass\n\ndef is_run_complete(run_dir: Path) -> bool:\n    if (run_dir / \"complete.txt\").exists():\n        return True\n    # robust fallback\n    needed = [\"best.pt\", \"final.pt\", \"params.json\", \"epoch_log.csv\"]\n    return all((run_dir / n).exists() for n in needed)\n\n# --- helpers to load best params JSON ---\ndef load_best_params_json(path_str: str, arch_name: str):\n    \"\"\"Return dict of best params for this arch, or global, or {} if unavailable.\"\"\"\n    if not path_str:\n        return {}\n    p = Path(os.path.expanduser(path_str))\n    if not p.exists():\n        if is_main:\n            print(f\"[WARN] best_params_json not found: {p}\")\n        return {}\n    try:\n        with open(p, \"r\") as f:\n            data = json.load(f)\n    except Exception as e:\n        if is_main:\n            print(f\"[WARN] failed to parse {p}: {e}\")\n        return {}\n    # If top-level looks like global (single set), return it\n    if any(k in data for k in [\"lr\", \"label_smoothing\", \"dropout\", \"weight_decay\", \"batch_size\"]):\n        return data\n    # Else assume per-arch mapping\n    return data.get(arch_name, {})\n\ndef pick_or_default(d, key, fallback):\n    v = d.get(key, None)\n    try:\n        return type(fallback)(v) if v is not None else fallback\n    except Exception:\n        return fallback\n\n# ----------------------------\n# Main\n# ----------------------------\ndef main():\n    set_seed(42)\n\n    proj_root = Path(os.path.expanduser(args.proj_root))\n    train_dir = proj_root / args.train_dir\n    test_dir = proj_root / args.test_dir\n    out_root = proj_root / args.results_subdir\n    if is_main:\n        out_root.mkdir(parents=True, exist_ok=True)\n\n    # Parse and de-dup extra tests vs main test_dir ---\n    main_test_abs = (proj_root / args.test_dir).resolve()\n    extra_tests = []  # list[(name, abs_path)]\n    if getattr(args, \"extra_tests\", \"\"):\n        parts = [p.strip() for p in args.extra_tests.split(\";\") if p.strip()]\n        for it in parts:\n            if \":\" in it:\n                name, rel = it.split(\":\", 1)\n            else:\n                # if no name given, derive from folder name\n                rel = it\n                name = Path(rel).name\n            p_abs = (proj_root / rel).resolve()\n            if p_abs == main_test_abs:\n                # skip duplicate of the primary test set\n                if is_main:\n                    print(f\"[extra_tests] Skipping '{name}' because it matches --test_dir\")\n                continue\n            extra_tests.append((name, p_abs))\n\n\n    # Dataset (ImageFolder) and stratified split of Luke 'train'\n    base_tf = transforms.Compose([transforms.ToTensor()])  # minimal just to read\n    base_ds = datasets.ImageFolder(str(train_dir), transform=base_tf)\n    class_names = base_ds.classes\n    y_all = np.array([y for _, y in base_ds.samples])\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=args.val_split, random_state=42)\n    train_idx, val_idx = next(sss.split(np.zeros(len(y_all)), y_all))\n\n    # Architecture list\n    ARCH_LIST = [\n        \"CNN_Small\",\n        \"ResNet50\", \"ResNet101\", \"ResNet152\",\n        \"DenseNet121\", \"DenseNet161\", \"DenseNet169\", \"DenseNet201\",\n        \"EffNetB0\",\n        \"MobileNetV2\", \"MobileNetV3_L\",\n        \"ResNeXt50_32x4d\", \"ResNeXt101_32x8d\",\n        \"VGG16\",\n        \"InceptionV3\",\n    ]\n\n    # Tiny per-arch sweep (or single-best)\n    if args.single_best_only:\n        LR_SCALE = [1.0]\n        def dp_candidates(arch, base_dp):  # single value\n            return [base_dp]\n    else:\n        LR_SCALE = [0.5, 1.0, 2.0]\n        def dp_candidates(arch, base_dp):\n            if \"EffNet\" in arch: return [0.0, min(0.2, base_dp)]\n            if arch == \"VGG16\":  return [0.5, max(0.3, base_dp)]\n            if arch == \"InceptionV3\": return [base_dp, 0.2]\n            return [base_dp, 0.0]\n\n    # Results aggregator\n    global_csv = out_root / \"arch_sweep_results.csv\"\n    if is_main and not global_csv.exists():\n        pd.DataFrame(columns=[\n            \"arch\", \"cfg_hash\", \"lr\", \"dropout\", \"weight_decay\", \"label_smoothing\", \"batch_size\",\n            \"best_val_acc\", \"best_epoch\", \"test_acc\", \"img_size\", \"run_dir\"\n        ]).to_csv(global_csv, index=False)\n\n    if is_main:\n        print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\") or \"<all visible>\")\n        print(\"CUDA available:\", torch.cuda.is_available(), \"| devices:\", torch.cuda.device_count())\n        if torch.cuda.is_available():\n            for i in range(torch.cuda.device_count()):\n                print(f\"  cuda:{i} -> {torch.cuda.get_device_name(i)}\")\n        print(f\"[rank {rank}] WORLD_SIZE={world_size} LOCAL_RANK={local_rank}\")\n\n    num_classes = len(class_names)\n    persistent_workers = False  # safer for long sweeps\n\n    for arch in ARCH_LIST:\n        # Pull best defaults for this arch (or global) if provided\n        best = load_best_params_json(args.best_params_json, arch)\n        lr_center = pick_or_default(best, \"lr\", args.best_lr)\n        label_smoothing = pick_or_default(best, \"label_smoothing\", args.best_label_smoothing)\n        base_dropout = pick_or_default(best, \"dropout\", args.best_dropout)\n        weight_decay = pick_or_default(best, \"weight_decay\", args.weight_decay)\n        base_batch_size = pick_or_default(best, \"batch_size\", args.batch_size)\n\n        for lr in [lr_center * s for s in LR_SCALE]:\n            for dp in dp_candidates(arch, base_dropout):\n                # Build config + hash (global→per-rank BS)\n                global_bs   = int(base_batch_size)\n                per_rank_bs = max(1, math.ceil(global_bs / max(1, world_size)))\n                bs_for_arch = per_rank_bs if arch != \"InceptionV3\" else max(2, per_rank_bs // 2)\n\n                if is_main:\n                    print(f\"[BS] arch={arch} world_size={world_size} global={global_bs} \"\n                          f\"per_rank={per_rank_bs} -> used={bs_for_arch}{' (Inception/2)' if arch=='InceptionV3' else ''}\")\n\n                cfg = {\n                    \"arch\": arch,\n                    \"lr\": float(lr),\n                    \"dropout\": float(dp),\n                    \"weight_decay\": float(weight_decay),\n                    \"label_smoothing\": float(label_smoothing),\n                    \"batch_size\": int(bs_for_arch),       # per-rank (kept for back-compat)\n                    \"global_batch_size\": int(global_bs),  # record intended global\n                    \"epochs\": int(args.epochs),\n                    \"val_split\": float(args.val_split),\n                }\n                cfg_hash = hash_config(cfg)\n                run_dir = out_root / arch / cfg_hash\n                if is_main:\n                    run_dir.mkdir(parents=True, exist_ok=True)\n\n                # Skip if completed\n                if args.skip_completed and is_run_complete(run_dir):\n                    if is_main:\n                        print(f\"[SKIP] {arch} cfg={cfg_hash} already complete.\")\n                    if using_ddp:\n                        dist.barrier()\n                    continue\n\n                # Build per-arch transforms\n                tf_train, tf_eval, size = make_transforms(arch)\n\n                # Real datasets\n                full_train_tf = datasets.ImageFolder(str(train_dir), transform=tf_train)\n                ds_train = Subset(full_train_tf, train_idx.tolist())\n                ds_val = Subset(datasets.ImageFolder(str(train_dir), transform=tf_eval), val_idx.tolist())\n                ds_test = datasets.ImageFolder(str(test_dir), transform=tf_eval)\n\n                # Samplers for DDP\n                if using_ddp and world_size > 1:\n                    #train_sampler = DistributedSampler(ds_train, num_replicas=world_size, rank=rank, shuffle=True, drop_last=False)\n                    train_sampler = DistributedSampler(ds_train, num_replicas=world_size, rank=rank, shuffle=True, drop_last=True)\n                    val_sampler   = DistributedSampler(ds_val,   num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n                    test_sampler  = DistributedSampler(ds_test,  num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n                else:\n                    train_sampler = None\n                    val_sampler = None\n                    test_sampler = None\n\n                # Loaders\n                train_loader = DataLoader(\n                    ds_train, batch_size=bs_for_arch,\n                    shuffle=(train_sampler is None),\n                    sampler=train_sampler,\n                    num_workers=args.num_workers, pin_memory=True, persistent_workers=persistent_workers,\n                    drop_last=True\n                )\n                val_loader = DataLoader(\n                    ds_val, batch_size=bs_for_arch,\n                    shuffle=False, sampler=val_sampler,\n                    num_workers=args.num_workers, pin_memory=True, persistent_workers=persistent_workers\n                )\n                test_loader = DataLoader(\n                    ds_test, batch_size=bs_for_arch,\n                    shuffle=False, sampler=test_sampler,\n                    num_workers=args.num_workers, pin_memory=False,  # safer for cleanup\n                    persistent_workers=False\n                )\n\n                # Build model\n                if arch == \"InceptionV3\":\n                    model = build_inception(num_classes)\n                else:\n                    builder = MODEL_REGISTRY_224[arch]\n                    model = builder(num_classes)\n                model = add_head_dropout(model, arch, dp, num_classes)\n                model = model.to(device)\n\n                # DDP wrap if applicable\n                if using_ddp and world_size > 1:\n                    model = DDP(model, device_ids=[local_rank], output_device=local_rank)\n\n                # Loss / Opt / Sched\n                ce = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n                    optimizer, mode=\"max\", factor=0.5, patience=3, min_lr=1e-6\n                )\n\n                # Logging (rank 0)\n                if is_main:\n                    params_path = run_dir / \"params.json\"\n                    with open(params_path, \"w\") as f:\n                        json.dump({**cfg, \"img_size\": int(size), \"run_dir\": str(run_dir)}, f, indent=2)\n\n                epoch_csv = run_dir / \"epoch_log.csv\"\n                best_path = run_dir / \"best.pt\"\n                final_path = run_dir / \"final.pt\"\n\n                best_val_acc = -1.0\n                best_epoch = -1\n                patience, wait = 8, 0\n\n                for epoch in range(1, args.epochs + 1):\n                    if using_ddp and world_size > 1 and isinstance(train_sampler, DistributedSampler):\n                        train_sampler.set_epoch(epoch)\n                    t0 = time.time()\n                    tr_loss, tr_acc = train_one_epoch(model, train_loader, ce, optimizer, device, arch)\n                    if using_ddp and world_size > 1 and isinstance(val_sampler, DistributedSampler):\n                        val_sampler.set_epoch(epoch)\n                    val_loss, val_acc = evaluate(model, val_loader, ce, device, arch)\n\n                    scheduler.step(val_acc)\n                    curr_lr = optimizer.param_groups[0][\"lr\"]\n\n                    # Epoch log row (rank 0)\n                    if is_main:\n                        row = {\n                            \"epoch\": epoch,\n                            \"train_loss\": tr_loss,\n                            \"val_loss\": val_loss,\n                            \"train_acc\": tr_acc,\n                            \"val_acc\": val_acc,\n                            \"lr\": curr_lr,\n                            \"secs\": time.time() - t0,\n                        }\n                        write_epoch_csv(epoch_csv, row)\n                        print(f\"[{arch} | {cfg_hash} | rank0] Epoch {epoch:02d}/{args.epochs} \"\n                              f\"train_acc={tr_acc:.4f} val_acc={val_acc:.4f} lr={curr_lr:.2e}\")\n\n                    # Early stopping & best save (rank 0)\n                    improved = val_acc > best_val_acc\n                    if improved:\n                        best_val_acc = val_acc\n                        best_epoch = epoch\n                        if is_main:\n                            to_save = model.module if isinstance(model, DDP) else model\n                            torch.save(to_save.state_dict(), best_path)\n                            print(f\"  ↑ New best {best_val_acc:.4f} @ epoch {epoch}; saved {best_path}\")\n                        wait = 0\n                    else:\n                        wait += 1\n                        if wait >= patience:\n                            if is_main:\n                                print(f\"  Early stop at epoch {epoch} (best {best_val_acc:.4f} @ {best_epoch})\")\n                            break\n\n                    if using_ddp:\n                        dist.barrier()\n\n                # Save final (rank 0)\n                if is_main:\n                    to_save = model.module if isinstance(model, DDP) else model\n                    torch.save(to_save.state_dict(), final_path)\n\n                if using_ddp:\n                    dist.barrier()\n\n                # Evaluate best on test (reload best weights into the object we call)\n                to_eval = model.module if isinstance(model, DDP) else model\n\n                if using_ddp and world_size > 1:\n                    # Load on rank0, then broadcast the Python object safely to all ranks\n                    if is_main:\n                        state_dict = torch.load(best_path, map_location=\"cpu\")  # CPU is fine for broadcast\n                    else:\n                        state_dict = None\n                    obj_list = [state_dict]\n                    dist.broadcast_object_list(obj_list, src=0)\n                    state_dict = obj_list[0]\n                    to_eval.load_state_dict(state_dict, strict=True)\n                else:\n                    # Single process (or no DDP)\n                    state_dict = torch.load(best_path, map_location=device)\n                    to_eval.load_state_dict(state_dict, strict=True)\n\n                if using_ddp and world_size > 1 and isinstance(test_sampler, DistributedSampler):\n                    test_sampler.set_epoch(0)\n                test_loss, test_acc = evaluate_on_test(to_eval, test_loader, device, arch)\n\n                # Extra test sets (optional)\n                extra_accs = {}\n                for et_name, et_path in extra_tests:\n                    et_ds   = datasets.ImageFolder(str(et_path), transform=tf_eval)\n                    if using_ddp and world_size > 1:\n                        et_sampler = DistributedSampler(et_ds, num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n                    else:\n                        et_sampler = None\n                    et_loader = DataLoader(et_ds, batch_size=bs_for_arch, shuffle=False, sampler=et_sampler,\n                                           num_workers=args.num_workers, pin_memory=False, persistent_workers=False)\n                    if using_ddp and world_size > 1 and isinstance(et_sampler, DistributedSampler):\n                        et_sampler.set_epoch(0)\n                    et_loss, et_acc = evaluate(to_eval, et_loader, ce, device, arch)\n                    extra_accs[f\"acc_{et_name}Test\"] = float(et_acc)\n\n                    shutdown_loader(et_loader)\n                    del et_loader, et_ds\n                # if args.extra_tests.strip():\n                    # pairs = [p for p in args.extra_tests.split(\";\") if p.strip()]\n                    # for pair in pairs:\n                        # name, path = pair.split(\":\", 1)\n                        # name = name.strip()\n                        # path = path.strip()\n                        # ds_extra = datasets.ImageFolder(str(proj_root / path), transform=tf_eval)\n                        # if using_ddp and world_size > 1:\n                            # sampler_extra = DistributedSampler(ds_extra, num_replicas=world_size, rank=rank,\n                                                               # shuffle=False, drop_last=False)\n                        # else:\n                            # sampler_extra = None\n                        # loader_extra = DataLoader(ds_extra, batch_size=bs_for_arch, shuffle=False,\n                                                  # sampler=sampler_extra, num_workers=args.num_workers,\n                                                  # pin_memory=False, persistent_workers=False)\n                        # if using_ddp and world_size > 1 and isinstance(sampler_extra, DistributedSampler):\n                            # sampler_extra.set_epoch(0)\n                        # _, acc_extra = evaluate(to_eval, loader_extra, ce, device, arch)\n                        # extra_accs[f\"acc_{name}Test\"] = float(acc_extra)\n                        # shutdown_loader(loader_extra)\n                        # del ds_extra, loader_extra\n                \n                # Update global CSV (rank 0)\n                if is_main:\n                    row_summary = {\n                        \"arch\": arch,\n                        \"cfg_hash\": cfg_hash,\n                        \"lr\": float(lr),\n                        \"dropout\": float(dp),\n                        \"weight_decay\": float(weight_decay),\n                        \"label_smoothing\": float(label_smoothing),\n                        \"batch_size\": int(bs_for_arch),\n                        \"best_val_acc\": float(best_val_acc),\n                        \"best_epoch\": int(best_epoch),\n                        \"test_acc\": float(test_acc),\n                        \"img_size\": int(size),\n                        \"run_dir\": str(run_dir),\n                    }\n                    \n                    if \"extra_accs\" in locals() and extra_accs:\n                        row_summary.update(extra_accs)\n                        \n                    df = pd.read_csv(global_csv)\n                    df = pd.concat([df, pd.DataFrame([row_summary])], ignore_index=True)\n                    df.to_csv(global_csv, index=False)\n                    (run_dir / \"complete.txt\").write_text(\"done\\n\")\n                \n                if using_ddp:\n                    dist.barrier()\n\n                # ---- Hard cleanup between configs to avoid FD/pin-memory leaks ----\n                shutdown_loader(train_loader)\n                shutdown_loader(val_loader)\n                shutdown_loader(test_loader)\n                del train_loader, val_loader, test_loader\n                del ds_train, ds_val, ds_test, full_train_tf\n                gc.collect()\n                torch.cuda.empty_cache()\n                # ------------------------------------------------------------------\n\n    if is_main:\n        print(\"\\nAll runs finished.\")\n        print(f\"Global results at: {global_csv}\")\n\n    if using_ddp:\n        dist.destroy_process_group()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "main()",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
