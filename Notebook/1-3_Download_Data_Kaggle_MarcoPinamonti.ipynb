{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Install required packages and mount Google Drive\n!pip install -q torch torchvision pandas numpy scikit-learn\nfrom google.colab import drive\ndrive.mount('/content/drive')"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "\n\"\"\"\nDownload Marco Pinamonti's dataset into /content/drive/MyDrive/Alzheimers/Data/Kaggle_MarcoPinamonti_Alzheimers_MRI,\nunzip, flatten \"Alzheimer_MRI_4_classes_dataset\", and rename class folders.\n\"\"\"\n\nimport os, sys, shutil, subprocess\nfrom pathlib import Path\n\nREPO = \"marcopinamonti/alzheimer-mri-4-classes-dataset\"\nPROJ_ROOT = Path(\"/content/drive/MyDrive/Alzheimers\")\nTARGET_DIRNAME = \"Kaggle_MarcoPinamonti_Alzheimers_MRI\"\n\nCLASS_MAP = {\n    \"MildDemented\": \"Mild_Impaired\",\n    \"ModerateDemented\": \"Moderate_Impaired\",\n    \"VeryMildDemented\": \"Very_Mild_Impaired\",\n    \"NonDemented\": \"No_Impairment\",\n}\n\ndef ensure_kaggle_cli():\n    try:\n        subprocess.run([\"kaggle\", \"--version\"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    except Exception:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n\ndef ensure_kaggle_creds():\n    kj = Path.home() / \".kaggle\" / \"kaggle.json\"\n    if not kj.exists() and not (os.getenv(\"KAGGLE_USERNAME\") and os.getenv(\"KAGGLE_KEY\")):\n        raise RuntimeError(\"Kaggle credentials not found.\")\n    if kj.exists():\n        os.chmod(kj, 0o600)\n\ndef unpack_all_archives(root: Path):\n    for pat in (\"*.zip\", \"*.tar\", \"*.tar.gz\", \"*.tgz\"):\n        for arc in root.rglob(pat):\n            shutil.unpack_archive(str(arc), str(arc.parent))\n            arc.unlink(missing_ok=True)\n\ndef flatten_and_rename(out_dir: Path):\n    inner = out_dir / \"Alzheimer_MRI_4_classes_dataset\"\n    if inner.exists() and inner.is_dir():\n        for child in inner.iterdir():\n            dst = out_dir / child.name\n            if dst.exists():\n                shutil.rmtree(dst, ignore_errors=True)\n            shutil.move(str(child), str(dst))\n        shutil.rmtree(inner, ignore_errors=True)\n\n    # Rename class dirs according to CLASS_MAP\n    for d in out_dir.iterdir():\n        if d.is_dir() and d.name in CLASS_MAP:\n            new_name = CLASS_MAP[d.name]\n            d.rename(d.parent / new_name)\n            print(f\"Renamed {d.name} -> {new_name}\")\n\ndef print_tiny_tree(root: Path):\n    for p in sorted(root.glob(\"*\")):\n        print(\" -\", p.name)\n\ndef main():\n    ensure_kaggle_cli(); ensure_kaggle_creds()\n    data_root = PROJ_ROOT / \"Data\"\n    out_dir = data_root / TARGET_DIRNAME\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    subprocess.check_call([\n        \"kaggle\", \"datasets\", \"download\",\n        \"-d\", REPO, \"-p\", str(out_dir), \"--unzip\"\n    ])\n\n    unpack_all_archives(out_dir)\n    flatten_and_rename(out_dir)\n    print(\"\\nFinal layout:\"); print_tiny_tree(out_dir)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "main()\n",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
